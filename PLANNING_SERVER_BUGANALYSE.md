# Planning Server â€” Bug-Analyse & LÃ¶sungsansÃ¤tze

**Stand:** 16.02.2026  
**Betrifft:** `planning_server.py` (aktuell: Commit `68aebac`) vs. Referenz `plan.py`  
**Model:** `2026-02-14/21-30-33` (1000 Episoden, ActInt2, 100 Epochen)

---

## Inhaltsverzeichnis

1. [Architektur-VerstÃ¤ndnis: Wie CEM wirklich funktioniert](#1-architektur-verstÃ¤ndnis)
2. [Bug-Katalog (vollstÃ¤ndig, mit Status)](#2-bug-katalog)
3. [Regressions-Analyse: Warum Loss von ~0.3 auf ~0.97?](#3-regressions-analyse)
4. [LÃ¶sungsansÃ¤tze (nach PrioritÃ¤t)](#4-lÃ¶sungsansÃ¤tze)

---

## 1. Architektur-VerstÃ¤ndnis

### Parallele Environments â‰  Echtzeit-Evaluation

Die `n_evals` parallelen Environments in `plan.py` sind **verschiedene Init/Goal-Paare**, NICHT verschiedene Rollout-Kandidaten fÃ¼r dasselbe Szenario:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CEM-Optimierung (rein im World Model, KEIN Env)        â”‚
â”‚                                                         â”‚
â”‚  300 Samples â†’ WM.rollout() â†’ Latent-Loss â†’ topk       â”‚
â”‚  Ergebnis: mu (bester Plan), sigma (Unsicherheit)       â”‚
â”‚  âŒ Echte Env wird hier NIE berÃ¼hrt                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ alle eval_every Steps
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Zwischen-Evaluation (echte Env, NUR Monitoring)        â”‚
â”‚                                                         â”‚
â”‚  mu in echter Env ausfÃ¼hren                             â”‚
â”‚  âŒ Ergebnis flieÃŸt NICHT zurÃ¼ck in mu/sigma            â”‚
â”‚  âœ… Nur: Monitoring, Early-Termination, Video-Vergleich â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Drei Pfade im Original-Code

| Pfad | CEM-Auswahl | Env-Nutzung | Feedback in Planner? |
|------|-------------|-------------|---------------------|
| **300 Samples** | WM-Rollout â†’ Latent-Loss â†’ topk | âŒ Nie in Env | â€” |
| **eval_every** | â€” | âœ… mu in Env ausfÃ¼hren | âŒ Nur Monitoring + Early Stop |
| **MPC** (`planning/mpc.py`) | CEM als Sub-Planner | âœ… Env-Rollout nach jedem MPC-Step | âœ… Neuer `obs_0` fÃ¼r nÃ¤chste CEM-Runde |

### Konsequenz fÃ¼r den Planning Server

Der Server hat **keine Env** â†’ weder `eval_every`-Monitoring noch MPC-Feedback mÃ¶glich. Das ist architekturbedingt korrekt: Der Isaac-Sim-Client Ã¼bernimmt die Rolle der Env und sendet nach jeder Aktion ein neues Bild â†’ "Client-seitiges MPC".

---

## 2. Bug-Katalog

### Ãœbersicht

| # | Bug | Schwere | Status | Commit |
|---|-----|---------|--------|--------|
| 1 | `model.eval()` nie aufgerufen | ğŸ”´ Kritisch | âœ… Gefixt | `68aebac` |
| 2 | `evaluator=None` â€” Kein Early-Stop | ğŸŸ¡ Performance | âœ… Bewusst akzeptiert | â€” |
| 3 | Warm-Start fÃ¼llt mit Nullen â†’ Null-Bias | ğŸ”´ Kritisch | âœ… Gefixt | `68aebac` |
| 4 | `empty_cache()` fragmentiert VRAM | ğŸŸ¡ Performance | âœ… Gefixt | `68aebac` |
| 5 | `__getattr__`-Fallback maskiert Fehler | ğŸŸ¡ Wartbarkeit | âœ… Gefixt | `68aebac` |
| 6 | Kein `torch.no_grad()` um CEM-Planner | âœ… Kein Bug | âœ… Korrekt | â€” |
| 7 | `img_to_obs` â€” Kein Bildformat-Handling | ğŸŸ¡ Robustheit | âš ï¸ Teilweise | `3b78dcb` |
| P | CEM-Parameter auf Paper-Werte | ğŸ”´ Kritisch | âœ… Gefixt | `68aebac` |

### Bug 1: `model.eval()` wird nie aufgerufen (âœ… GEFIXT)

**Datei:** `planning_server.py:130`  
**Problem:** `VWorldModel.train()` (in `models/visual_world_model.py:78-86`) aktiviert Training-Modi fÃ¼r alle Sub-Module (Encoder, Predictor, Proprio/Action-Encoder). Obwohl DINOv2 LayerNorm statt BatchNorm nutzt, kÃ¶nnen:

- Dropout-Layer im Predictor stochastische Ausgaben erzeugen
- Stochastische Regularisierung in Action/Proprio-Encodern das Ergebnis verfÃ¤lschen

`plan.py` hat das gleiche Problem â€” aber dort wird das Modell nur einmal genutzt. Im Server bleibt es persistent, und die Stochastik akkumuliert sich Ã¼ber viele Requests.

**Fix:** 1 Zeile nach Model-Laden:
```python
model.eval()  # WICHTIG: Eval-Modus fuer deterministische Inferenz
```

**Auswirkung auf Loss:** Gering. DINOv2 hat kein BatchNorm, und der Predictor hat (je nach Konfiguration) minimalen Dropout. ErklÃ¤rt **nicht** den Loss-Anstieg von 0.3 â†’ 0.97.

---

### Bug 2: `evaluator=None` â€” Keine Early-Termination (âœ… Bewusst akzeptiert)

**Datei:** `planning_server.py:285`  
**Im Original:** `planning/cem.py:105-113` prÃ¼ft `if self.evaluator is not None` und fÃ¼hrt die aktuellen besten Actions in der echten Env aus. Bei Erfolg wird CEM vorzeitig beendet.

**Im Server:** `evaluator=None` â†’ CEM lÃ¤uft **immer** alle `opt_steps` Iterationen durch, auch wenn der Plan bereits nach 3 Schritten konvergiert hat.

**Auswirkung:**
- âŒ Kein QualitÃ¤tsproblem (mehr Iterationen kÃ¶nnen nicht schaden)
- âš ï¸ Performance-Problem (unnÃ¶tige GPU-Zeit bei konvergierten PlÃ¤nen)
- âŒ Keine Validierung ob der Plan in der echten Physik funktioniert

**Status:** Kein Fix nÃ¶tig. Early-Termination spart nur Zeit, nicht QualitÃ¤t. Das Client-seitige MPC Ã¼bernimmt die Env-Validation.

---

### Bug 3: Warm-Start fÃ¼llt mit Nullen auf â†’ Null-Bias (âœ… GEFIXT)

**Datei:** `planning_server.py:399` (alter Code)  
**Problem:** Beim MPC-Warm-Start wird der vorherige Plan um 1 Step geshiftet. Die fehlende letzte Action wurde mit `torch.zeros()` aufgefÃ¼llt:

```python
# ALT (Bug):
zero_tail = torch.zeros(1, 1, warm_start_actions.shape[2])
actions_init = torch.cat([shifted, zero_tail], dim=1)

# NEU (Fix):
last_action = warm_start[:, -1:, :]  # Letzte bekannte Action wiederholen
actions_init = torch.cat([shifted, last_action], dim=1)
```

**Warum ist `[0,0,...,0]` schlecht?** Im z-normalisierten Raum bedeutet Null "bewege dich zum Mittelwert aller Trainingsaktionen". Der CEM startet dann mit einem Plan, dessen letzte Aktion systematisch in Richtung Mittelwert verzerrt ist. Bei `opt_steps=5` (Online-Modus) hat CEM zu wenig Iterationen um diesen Bias zu Ã¼berwinden.

**Auswirkung auf Loss:** Moderat. Betrifft nur MPC-Sequenzen (ab dem 2. plan()-Aufruf). ErklÃ¤rt nicht den Loss bei der ersten Planung.

---

### Bug 4: `torch.cuda.empty_cache()` zwischen Chunks fragmentiert VRAM (âœ… GEFIXT)

**Datei:** `planning_server.py:187` (alter Code im `ChunkedRolloutWrapper`)  
**Problem:** `empty_cache()` gibt den CUDA-Cache frei, aber die akkumulierten Ergebnis-Tensoren (`all_z_obses`, `all_zs`) bleiben alloziert. Der nÃ¤chste Chunk muss neuen Speicher anfordern â†’ Fragmentierung. Bei vielen Chunks kann das paradoxerweise zu **mehr** OOM fÃ¼hren statt weniger.

**Fix:** `empty_cache()` nur einmal NACH der gesamten Chunk-Schleife aufrufen:
```python
# Nach der for-Schleife, vor dem return:
if torch.cuda.is_available():
    torch.cuda.empty_cache()
```

**Auswirkung auf Loss:** Keine (rein Performance/StabilitÃ¤t).

---

### Bug 5: `__getattr__`-Fallback im `ChunkedRolloutWrapper` (âœ… GEFIXT)

**Datei:** `planning_server.py:162-166`  
**Problem:** Jeder Attributzugriff, der nicht explizit gesetzt ist, wird an `self._model` delegiert. Wenn `self._model` das Attribut auch nicht hat, kommt ein kryptischer Fehler aus dem Model statt aus dem Wrapper. AuÃŸerdem: `nn.Module`-Methoden wie `state_dict()`, `parameters()`, `to()` werden stillschweigend durchgereicht, was dazu fÃ¼hren kann, dass z.B. `model.to('cpu')` den Wrapper intakt lÃ¤sst aber das innere Model verschiebt.

**Fix:** Explizite Forwarding-Methoden fÃ¼r kritische Operationen:
```python
def to(self, *args, **kwargs):
    self._model.to(*args, **kwargs)
    return self

def state_dict(self, *args, **kwargs):
    return self._model.state_dict(*args, **kwargs)
```

**Auswirkung auf Loss:** Keine (Wartbarkeit/Debugging).

---

### Bug 6: Kein `torch.no_grad()` um den CEM-Planner (âœ… KEIN BUG)

**Datei:** `planning_server.py:404`  
**Status:** Der Ã¤uÃŸere `torch.no_grad()` im Server schÃ¼tzt auch den `transform_obs()`- und `encode_obs()`-Aufruf. Innerhalb von `CEMPlanner.plan()` in `planning/cem.py:94` steht ebenfalls `with torch.no_grad()`. Doppelter Kontext ist harmlos.

---

### Bug 7: `img_to_obs` â€” Kein Handling von BildgrÃ¶ÃŸe/Kamera-Diskrepanzen (âš ï¸ TEILWEISE)

**Datei:** `planning_server.py:310-326`  
**Problem:** Das Bild wird roh Ã¼bergeben â€” keine ÃœberprÃ¼fung ob:
- Die AuflÃ¶sung zur TrainingsauflÃ¶sung passt (224Ã—224)
- Das Farbformat stimmt (BGR vs RGB)
- Der Wertebereich korrekt ist

Der `Preprocessor.transform_obs()` macht `/255.0` und `transform` (Resize + CenterCrop + Normalize) â€” aber das nimmt an, dass die Eingabe `uint8 [0-255]` im Format `(B, T, H, W, C)` ist. Wenn das Isaac-Sim-Bild z.B. `float32 [0-1]` oder `(H, W, 4)` (RGBA) liefert, stimmt die Pipeline nicht.

**Aktueller Status:** Teilfix vorhanden â€” `img_to_obs()` konvertiert jetzt `float32 â†’ uint8`, aber keine RGBA-Erkennung, keine BGR-PrÃ¼fung, keine AuflÃ¶sungs-Validierung.

**Auswirkung auf Loss:** Kann katastrophal sein, wenn das Bildformat nicht stimmt. Aber das war auch im alten Code so â†’ erklÃ¤rt nicht die Regression.

---

## 3. Regressions-Analyse: Warum Loss von ~0.3 auf ~0.97?

### Fakten

| Metrik | Alter Server (Referenz) | Neuer Server (nach Bugfixes) |
|--------|-------------------------|------------------------------|
| Modell | `2026-02-09/17-59-59` (500ep, ActInt10, 50 Epochen) | `2026-02-14/21-30-33` (1000ep, ActInt2, 100 Epochen) |
| CEM-Parameter | `samples=300, steps=30, topk=30, H=5` | `samples=300, steps=30, topk=30, H=5` |
| Initial Loss | ~0.83 | ~1.90 |
| Final Loss | **~0.34** | **~0.98** |
| Reduktion | 58.9% | 48.6% |

### âš ï¸ Die Bugfixes sind NICHT die Ursache der Regression!

Die Bugfixes (`model.eval()`, Warm-Start, Cache) kÃ¶nnen den Loss nur **senken**, nicht erhÃ¶hen. Der Anstieg kommt vom **anderen Modell**:

### MÃ¶gliche Ursachen (Modell-bezogen)

**Hypothese A: Anderes Modell, anderer Loss-Raum**
- Das neue Modell (`2026-02-14/21-30-33`) wurde mit 1000 Episoden / ActInt2 / 100 Epochen trainiert
- Das alte Modell (`2026-02-09/17-59-59`) mit 500 Episoden / ActInt10 / 50 Epochen
- Ein anderer Datensatz mit anderer Aktions-Verteilung erzeugt einen **anderen Latent-Raum**
- Die absolute Loss-HÃ¶he ist zwischen Modellen **nicht vergleichbar**
- Ein Loss von 0.97 im neuen Modell kann qualitativ besser sein als 0.34 im alten

**Hypothese B: Zu kurze Trainingszeit / Underfit**
- 100 Epochen bei 1000 Episoden = weniger Passes pro Episode als 50 Epochen bei 500 Episoden
- Der Encoder/Predictor hat den feineren ActInt2-Datensatz mÃ¶glicherweise nicht genug gelernt
- PrÃ¼fbar: Training-Loss-Kurve des neuen Modells ansehen

**Hypothese C: ActInt2 Ã¤ndert die Aktions-Dynamik**
- ActInt2 (alle 4 Sim-Steps) erzeugt feinere aber kleinere Aktionen als ActInt10 (alle 20 Sim-Steps)
- Die Action-Varianz ist geringer â†’ z-Normalisierung komprimiert den Raum stÃ¤rker
- CEM muss in einem "dichteren" Raum mit feineren Unterschieden optimieren
- Das erfordert mÃ¶glicherweise **mehr Samples oder Steps** fÃ¼r gleiche Konvergenz

**Hypothese D: Dataset-Statistik-Diskrepanz**
- **Kritisch zu prÃ¼fen:** Die `action_mean`/`action_std` im Output des Servers:
  ```
  Mean: [0.47974253 0.01700846 0.16120689 0.4795267  0.01707228 0.16092643]
  Std:  [0.12250879 0.16102357 0.07198107 0.12270366 0.16116358 0.07203   ]
  ```
- Wenn diese nicht zu den im Training verwendeten Werten passen â†’ falsche Normalisierung â†’ hoher Loss
- **Der Server lÃ¤dt jetzt alle 999 Episoden** fÃ¼r die Statistik-Berechnung (via `FrankaCubeStackDataset` mit `preload_images=False`), wÃ¤hrend der alte Server `hydra.utils.call()` nutzte, das ein Train/Val-Split machte
- **â†’ Unterschiedliche mean/std wenn der Split einen Subset verwendet!**

### ğŸ”´ Wahrscheinlichste Ursache: Hypothese D â€” Dataset-Split-Diskrepanz

**Alt (`.bak`):**
```python
_datasets, _traj_dset = hydra.utils.call(
    model_cfg.env.dataset,
    num_hist=model_cfg.num_hist,
    num_pred=model_cfg.num_pred,
    frameskip=model_cfg.frameskip,
)
_dset_val = _traj_dset["valid"]
action_mean_base = _dset_val.action_mean.clone()  # Statistik vom VAL-Split
```

**Neu (aktuell):**
```python
_full_dset = FrankaCubeStackDataset(
    n_rollout=_dset_cfg.get("n_rollout", None),
    data_path=_dset_cfg["data_path"],
    preload_images=False,
)
action_mean = _full_dset.action_mean.clone()  # Statistik von ALLEN Episoden
```

**Problem:** Das Modell wurde mit den Statistiken des **Train-Splits** trainiert. Der Server berechnet jetzt die Statistiken Ã¼ber **alle Episoden** (kein Split). Wenn Train- und Full-Statistiken sich unterscheiden:

- `(action - wrong_mean) / wrong_std` â‰  `(action - correct_mean) / correct_std`
- Jede Normalisierung/Denormalisierung ist systematisch verschoben
- Der CEM-Suchraum liegt neben dem tatsÃ¤chlich gelernten Raum
- â†’ HÃ¶herer Loss, weil die Aktionen "daneben" liegen

### Verifikation

PrÃ¼fen ob die Statistiken Ã¼bereinstimmen:
```bash
python -c "
import torch, hydra
from omegaconf import OmegaConf

cfg = OmegaConf.load('outputs/2026-02-14/21-30-33/hydra.yaml')
_, dset = hydra.utils.call(cfg.env.dataset, num_hist=cfg.num_hist, num_pred=cfg.num_pred, frameskip=cfg.frameskip)
dset_val = dset['valid']
print('Val-Split mean:', dset_val.action_mean.numpy())
print('Val-Split std:', dset_val.action_std.numpy())
"
```
Dann vergleichen mit den Server-Werten oben. Wenn sie abweichen â†’ **das ist die Root Cause**.

---

## 4. LÃ¶sungsansÃ¤tze (nach PrioritÃ¤t)

### âœ… Bereits umgesetzt: CEM-Parameter auf Paper-Werte

`samples=300, steps=30, topk=30, horizon=5` â€” argparse-Defaults korrigiert.

### âœ… Bereits umgesetzt: Ansatz 1 â€” Minimaler Bugfix

| Fix | Zeilen | Wo | Status |
|-----|--------|----|--------|
| `model.eval()` | 1 | nach `load_model()` | âœ… |
| Warm-Start: `repeat` statt Nullen | 1 | `zero_tail` â†’ `warm_start[:, -1:]` | âœ… |
| `empty_cache()` nur am Ende | 2 | `ChunkedRolloutWrapper.rollout()` | âœ… |
| Explizites Forwarding im Wrapper | 8 | `to()`, `state_dict()`, `eval()` etc. | âœ… |

### Ansatz 2: Loss-basiertes Early Stopping (~20 Zeilen)

Statt `evaluator=None` einen simplen Konvergenz-Check im `LoggingRun` einbauen:

```python
class LoggingRun:
    def __init__(self, patience=5, min_improvement=0.001):
        self._losses = []
        self._patience = patience
        self._min_improvement = min_improvement
    
    def should_stop(self):
        if len(self._losses) < self._patience + 1:
            return False
        recent = self._losses[-self._patience:]
        improvement = (recent[0] - recent[-1]) / recent[0]
        return improvement < self._min_improvement
```

**Aufwand:** ~20 Zeilen. Erfordert Anpassung von `cem.py` oder einen Callback-Hook.  
**Nutzen:** Spart Rechenzeit bei konvergierten PlÃ¤nen. Kein QualitÃ¤tsgewinn.  
**PrioritÃ¤t:** Niedrig.

### ğŸ”´ Ansatz 3: Dataset-Statistiken korrekt laden (DRINGEND)

**Das vermutete Root-Cause-Problem:** Der Server berechnet mean/std Ã¼ber **alle** Episoden, das Training aber nur Ã¼ber den **Train-Split**.

**Fix:** ZurÃ¼ck zum alten Dataset-Loading, aber mit `preload_images=False`:

```python
# Variante A: Hydra-Call wie bisher, aber ohne Bilder
_datasets, _traj_dset = hydra.utils.call(
    model_cfg.env.dataset,
    num_hist=model_cfg.num_hist,
    num_pred=model_cfg.num_pred,
    frameskip=model_cfg.frameskip,
)
_dset_val = _traj_dset["valid"]  # â† GLEICHER Split wie beim Training!
action_mean = _dset_val.action_mean.clone()
action_std = _dset_val.action_std.clone()
# ... etc.
del _dset_val, _traj_dset, _datasets

# Variante B: FrankaCubeStackDataset direkt, ABER mit gleichem Split
# â†’ Erfordert, dass der Split reproduzierbar ist (gleiche n_rollout, gleicher seed)
```

**Aufwand:** ~5 Zeilen Ã¤ndern.  
**Auswirkung:** Wenn dies die Root Cause ist â†’ Loss sollte wieder auf ~0.3 fallen.  
**PrioritÃ¤t:** ğŸ”´ HÃ¶chste PrioritÃ¤t. Sofort testen.

### Ansatz 4: Server-seitige MPC-Logik (~50 Zeilen)

Den bestehenden `plan â†’ execute â†’ plan`-Loop im Client in den Server verlagern:

```
Client                          Server
  â”‚ send(image, goal)             â”‚
  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>       â”‚
  â”‚                               â”‚ CEM plan (H=5)
  â”‚                               â”‚ nimm action[0]
  â”‚     <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
  â”‚ receive(action[0])            â”‚
  â”‚ execute in Isaac Sim          â”‚
  â”‚ send(new_image)               â”‚
  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>       â”‚
  â”‚                               â”‚ CEM replan ab new_image
  â”‚                               â”‚ mit Warm-Start
  â”‚     <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
  â”‚ receive(action[0])            â”‚
  â”‚ ...                           â”‚
```

Das ist konzeptionell das, was `MPCPlanner` in `planning/mpc.py` tut â€” aber ohne dass der Server selbst die Env braucht. **Genau dieses Pattern ist bereits im `cmd == "plan"` Handler implementiert** (mit Warm-Start). Der einzige Unterschied: die MPC-Logik liegt im **Client**, nicht im Server.

**Aufwand:** ~50 Zeilen Server-Code.  
**Nutzen:** Beste QualitÃ¤t, weil der Planner den echten Zustand nach jeder Aktion sieht.  
**PrioritÃ¤t:** Mittel. Funktionell bereits Ã¼ber Client-MPC gelÃ¶st.

---

## Zusammenfassung: NÃ¤chste Schritte

| PrioritÃ¤t | Aktion | Erwarteter Effekt |
|-----------|--------|-------------------|
| ğŸ”´ **1** | PrÃ¼fen ob `action_mean/std` zwischen Full-Dataset und Train-Split abweichen | Root-Cause der Regression identifizieren |
| ğŸ”´ **2** | Falls ja: Dataset-Loading auf `hydra.utils.call()` mit Train/Val-Split zurÃ¼ckstellen | Loss zurÃ¼ck auf ~0.3 Level |
| ğŸŸ¡ **3** | Training-Loss-Kurve des neuen Modells prÃ¼fen (konvergiert?) | Underfit ausschlieÃŸen |
| ğŸŸ¢ **4** | Loss-basiertes Early Stopping (optional) | Nur Speedup, keine QualitÃ¤t |
| ğŸŸ¢ **5** | Server-seitige MPC-Logik (optional) | Bereits via Client-MPC umgesetzt |
